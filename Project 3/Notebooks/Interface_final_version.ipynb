{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f901eca5-9e17-4f62-af87-0d0179bf5007",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_features, num_classes)\n\u001b[0;32m     36\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 37\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Resnet_Final_version_25.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Define the transformations for test data\u001b[39;00m\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[0;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[1;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[1;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[1;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[1;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[1;34m(location)\u001b[0m\n\u001b[0;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Imports for Interface\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "from tkinter import ttk, messagebox\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "# Constants and hyperparameters\n",
    "num_classes = 2\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "\n",
    "# Load the pre-trained ResNet model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./Resnet_Final_version_25.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Define the transformations for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "test_dir = \"./../../Project 3/Test_2_klas\"\n",
    "test_dataset = ImageFolder(test_dir, transform=transform_test)\n",
    "        \n",
    "test_dataset = list(test_dataset)\n",
    "test_dataset = random.sample(test_dataset, k=100)\n",
    "\n",
    "# Create a DataLoader for managing the test data batches\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate over the test data and make predictions\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(inputs)\n",
    "    output = torch.argmax(torch.exp(output), dim=1).cpu().numpy()\n",
    "    y_pred.extend(output)\n",
    "    labels = labels.cpu().numpy()\n",
    "    y_true.extend(labels)\n",
    "\n",
    "\n",
    "def show_error(error_message):\n",
    "    messagebox.showerror('Input Error', f'Error: {error_message}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f9f86-df1d-4c8a-80a7-f490228cfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Run(*args):\n",
    "    try:\n",
    "        \n",
    "        b_s = int(batch_size_2.get())\n",
    "        if not 250 <= b_s <= 500:\n",
    "            show_error(f'Batch size have to be between 250 to 500')\n",
    "            return\n",
    "        s_s = int(sample_size_2.get())\n",
    "        if not 5 <= s_s <= 100:\n",
    "            show_error(f'Sample size have to be between 5 to 100')\n",
    "            return\n",
    "        n_r = int(nr_runs.get())\n",
    "        if not 1 <= n_r <= 100:\n",
    "            show_error(f'Number of runs have to be between 1 to 100')\n",
    "            return\n",
    "        u_a = float(user_aql.get())\n",
    "        if not 0 < u_a < 100:\n",
    "            show_error(f'Your AQL have to be between 1 to 100')\n",
    "            return\n",
    "\n",
    "        # Calculate the percentage of bad apples\n",
    "        bach_size_32 = random.sample(y_pred, k=b_s)\n",
    "        sample32 = random.sample(bach_size_32, k=s_s*n_r)\n",
    "        Rot_Apple = sample32.count(1)\n",
    "        Normal_Apple = sample32.count(0)\n",
    "        perc_bad_apples = (Rot_Apple / len(sample32)) * 100\n",
    "\n",
    "        # Classify the batch based on the percentage of bad apples\n",
    "        if perc_bad_apples <= u_a:\n",
    "            answer_1 = 'Class 1: Go to the supermarket'\n",
    "        elif u_a < perc_bad_apples < 6.5:\n",
    "            answer_1 = 'Class 2: Go to the applesauce factory'\n",
    "        elif 6.5 <= perc_bad_apples < 15:\n",
    "            answer_1 = 'Class 3: Go to the apple syrup factory'\n",
    "        else:\n",
    "            answer_1 = 'Class 4: Feed them to the pigs!'\n",
    "            \n",
    "        # Pie chart visualization for the types of apples\n",
    "        labels = ['Normal', 'Rotten']\n",
    "        sizes = [Normal_Apple, Rot_Apple]\n",
    "        plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "        plt.axis('equal')  # Equal aspect ratio = drawn as a circle.\n",
    "        plt.title('Distribution of Apple Types')\n",
    "        plt.savefig('./pie_chart.png')\n",
    "\n",
    "        good_apple_percentage.set(f\"{str(100 - perc_bad_apples)} %\")\n",
    "        test_accuracy.set(f\"{str(99.89)} %\")\n",
    "        group_apple_category.set(str(answer_1))\n",
    "        \n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_answer(*args):\n",
    "    try:\n",
    "        b_s = int(batch_size_2.get())\n",
    "        s_s = int(sample_size_2.get())\n",
    "        n_r = int(nr_runs.get())\n",
    "        u_a = float(user_aql.get())\n",
    "        \n",
    "        # Calculate the percentage of bad apples\n",
    "        bach_size_32 = random.sample(y_pred, k=b_s)\n",
    "        sample32 = random.sample(bach_size_32, k=s_s*n_r)\n",
    "        Rot_Apple = sample32.count(1)\n",
    "        perc_bad_apples = (Rot_Apple / len(sample32)) * 100\n",
    "\n",
    "        # Classify the batch based on the percentage of bad apples\n",
    "        if perc_bad_apples <= u_a:\n",
    "            answer_1 = 'Class 1: Go to the supermarket'\n",
    "        elif u_a < perc_bad_apples < 6.5:\n",
    "            answer_1 = 'Class 2: Go to the applesauce factory'\n",
    "        elif 6.5 <= perc_bad_apples < 15:\n",
    "            answer_1 = 'Class 3: Go to the apple syrup factory'\n",
    "        else:\n",
    "            answer_1 = 'Class 4: Feed them to the pigs!'\n",
    "        \n",
    "        \n",
    "        # Load the pre-trained sentence transformer model\n",
    "        model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "        \n",
    "        # Define a dictionary of questions and answers\n",
    "        qa_pairs = {\n",
    "            \"Can you tell me the total number of apples in the batch?\": f\"The total number of apples in the batch is {b_s}.\",\n",
    "            \"What is the percentage of bad apples?\": f\"The percentage of bad apples is {perc_bad_apples:.2f}%.\",\n",
    "            \"How many bad apples are there in an approved batch?\": f\"The number of bad apples in an approved batch is {Rot_Apple}.\",\n",
    "            \"How many apples are categorized as blotch?\": f\"The number of apples categorized as blotch is {Rot_Apple}.\",\n",
    "            \"What is the proportion of rotten apples?\": f\"The proportion of rotten apples is {Rot_Apple / len(sample32):.2f}.\",\n",
    "            \"Can we use this apple batch to make apple mousse?\": \"Yes, we can use this apple batch to make apple mousse.\",\n",
    "            \"Are there enough healthy apples to make apple sauce?\": \"To make apple sauce, we need to evaluate the number of healthy apples based on the desired quantity.\",\n",
    "            \"Can we use this batch for the supermarket if the acceptance quality is increased by 1 percentage for the klasse 1?\": f\"If the acceptance quality is increased by 1 percentage for klasse 1, we can use this batch for the supermarket.\",\n",
    "            \"Does the quality of the batch increase when the batch size is increased?\": \"The quality of the batch may or may not increase when the batch size is increased. It depends on various factors.\",\n",
    "            \"Whatâ€™s the average ratio between the healthy and unhealthy apples for different sample sizes?\": \"The average ratio between healthy and unhealthy apples can be calculated based on different sample sizes.\"\n",
    "        }\n",
    "\n",
    "        # Calculate sentence embeddings for the questions\n",
    "        question_embeddings = model.encode(list(qa_pairs.keys()))\n",
    "        \n",
    "        def get_answer_2(user_query):\n",
    "            query_embedding = model.encode([user_query]).flatten()  # Flatten the query_embedding\n",
    "            similarities = [1 - cosine(query_embedding, q_emb) for q_emb in question_embeddings]\n",
    "            most_similar_idx = similarities.index(max(similarities))\n",
    "            return qa_pairs[list(qa_pairs.keys())[most_similar_idx]]\n",
    "\n",
    "        # Chat bot loop\n",
    "        \n",
    "        user_query = str(chat_bot_box.get())\n",
    "        if user_query.lower() == \"exit\":\n",
    "            answer_2 = \"Chat bot: Goodbye!\"\n",
    "        else:\n",
    "            response = get_answer_2(user_query)\n",
    "            answer_2 = f\"Chat bot: {response}.\"\n",
    "        \n",
    "        chat_bot_answer.set(answer_2)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "# Creating method for adding picture\n",
    "def on_click():\n",
    "    global my_img\n",
    "    top = Toplevel()\n",
    "    top.title('Genetic')\n",
    "    my_img = ImageTk.PhotoImage(Image.open('./pie_chart.png'))\n",
    "    Label(top, image=my_img).pack()\n",
    "    \n",
    "# Building interface\n",
    "root = Tk()\n",
    "root.title('Apple qualifier')\n",
    "\n",
    "# Font properties\n",
    "s = ttk.Style()\n",
    "font_1 = ('Ariel Nova', 20)\n",
    "s.configure('.', font = font_1)\n",
    "\n",
    "mainframe = ttk.Frame(root, padding='3 3 12 12')\n",
    "mainframe.grid(column=0, row=0, sticky=(N, W, E, S))\n",
    "root.columnconfigure(0, weight=1)\n",
    "root.rowconfigure(0, weight=1)    \n",
    "\n",
    "batch_size_2 = StringVar()\n",
    "batch_size_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=batch_size_2)\n",
    "batch_size_entry.grid(column=2, row=1, sticky=(W, E))\n",
    "\n",
    "sample_size_2 = StringVar()\n",
    "sample_size_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=sample_size_2)\n",
    "sample_size_entry.grid(column=2, row=2, sticky=(W, E))\n",
    "\n",
    "nr_runs = StringVar()\n",
    "nr_runs_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=nr_runs)\n",
    "nr_runs_entry.grid(column=2, row=3, sticky=(W, E))\n",
    "\n",
    "user_aql = StringVar()\n",
    "user_aql_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=user_aql)\n",
    "user_aql_entry.grid(column=2, row=4, sticky=(W, E))\n",
    "\n",
    "# Calculating Button (lower right)\n",
    "good_apple_percentage = StringVar()\n",
    "ttk.Label(mainframe, textvariable=good_apple_percentage).grid(column=2, row=6, sticky=(W, E))\n",
    "\n",
    "test_accuracy = StringVar()\n",
    "ttk.Label(mainframe, textvariable=test_accuracy).grid(column=2, row=7, sticky=(W, E))\n",
    "\n",
    "group_apple_category = StringVar()\n",
    "ttk.Label(mainframe, textvariable=group_apple_category).grid(column=2, row=8, sticky=(W, E))\n",
    "\n",
    "# chat bot box\n",
    "chat_bot_box = StringVar()\n",
    "chat_bot_box_entry = ttk.Entry(mainframe, width=50, font = font_1, textvariable=chat_bot_box)\n",
    "chat_bot_box_entry.grid(column=1, row=10, sticky=(W, E))\n",
    "\n",
    "chat_bot_answer = StringVar()\n",
    "ttk.Label(mainframe, textvariable=chat_bot_answer).grid(column=1, row=11, sticky=(W, E))\n",
    "\n",
    "# Building interface Buttons\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=1, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=2, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=3, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=4, sticky=W)\n",
    "ttk.Button(mainframe, text='Run', command=Run).grid(column=3, row=5, sticky=W)\n",
    "ttk.Button(mainframe, text='Chart', command=on_click).grid(column=3, row=6, sticky=W)\n",
    "\n",
    "\n",
    "ttk.Button(mainframe, text='Run chat', command=get_answer).grid(column=3, row=10, sticky=W)\n",
    "ttk.Label(mainframe, text='Please ask me a questions:').grid(column=1, row=9, sticky=W)\n",
    "\n",
    "# Information Labels for Input Data Buttons\n",
    "ttk.Label(mainframe, text='The batch size is:').grid(column=1, row=1, sticky=W)\n",
    "ttk.Label(mainframe, text='The sample size is:').grid(column=1, row=2, sticky=W)\n",
    "ttk.Label(mainframe, text='The number of sample run is:').grid(column=1, row=3, sticky=W)\n",
    "ttk.Label(mainframe, text='The percentage of AQL is:').grid(column=1, row=4, sticky=W)\n",
    "ttk.Label(mainframe, text='The percentage of good appels is:').grid(column=1, row=6, sticky=W)\n",
    "ttk.Label(mainframe, text='Test accuracy is:').grid(column=1, row=7, sticky=W)\n",
    "ttk.Label(mainframe, text='The apple group category is:').grid(column=1, row=8, sticky=W)\n",
    "\n",
    "# Interface INPUT loop and OUTPUT\n",
    "for child in mainframe.winfo_children(): \n",
    "    child.grid_configure(padx=30, pady=15)\n",
    "\n",
    "batch_size_entry.focus()\n",
    "sample_size_entry.focus()\n",
    "nr_runs_entry.focus()\n",
    "user_aql_entry.focus()\n",
    "root.bind('<Return>', Run)\n",
    "\n",
    "chat_bot_box_entry.focus()\n",
    "root.bind('<Return>', get_answer)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e567a-88a5-4c35-930f-b57f6c4a729c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
