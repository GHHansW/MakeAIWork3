{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308dd2a6-623a-4649-b1f7-c9ae5ad0ecfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HansW\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HansW\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32: Train Loss: 1.4859, Test Loss: 5.6444, Test Accuracy: 60.00%\n",
      "Epoch 2/32: Train Loss: 1.2595, Test Loss: 1.0689, Test Accuracy: 57.14%\n",
      "Epoch 3/32: Train Loss: 1.2258, Test Loss: 1.4308, Test Accuracy: 68.57%\n",
      "Epoch 4/32: Train Loss: 0.9565, Test Loss: 1.0039, Test Accuracy: 62.86%\n",
      "Epoch 5/32: Train Loss: 0.8941, Test Loss: 0.6919, Test Accuracy: 71.43%\n",
      "Epoch 6/32: Train Loss: 0.8782, Test Loss: 1.6320, Test Accuracy: 51.43%\n",
      "Epoch 7/32: Train Loss: 0.9902, Test Loss: 0.6374, Test Accuracy: 80.00%\n",
      "Epoch 8/32: Train Loss: 0.7125, Test Loss: 0.9172, Test Accuracy: 65.71%\n",
      "Epoch 9/32: Train Loss: 0.6912, Test Loss: 1.4379, Test Accuracy: 57.14%\n",
      "Epoch 10/32: Train Loss: 0.6407, Test Loss: 0.7660, Test Accuracy: 71.43%\n",
      "Epoch 11/32: Train Loss: 0.5524, Test Loss: 0.5573, Test Accuracy: 80.00%\n",
      "Epoch 12/32: Train Loss: 0.4447, Test Loss: 0.5588, Test Accuracy: 85.71%\n",
      "Epoch 13/32: Train Loss: 0.4644, Test Loss: 0.5361, Test Accuracy: 80.00%\n",
      "Epoch 14/32: Train Loss: 0.3970, Test Loss: 0.4238, Test Accuracy: 82.86%\n",
      "Epoch 15/32: Train Loss: 0.3241, Test Loss: 0.4592, Test Accuracy: 82.86%\n",
      "Epoch 16/32: Train Loss: 0.3002, Test Loss: 0.3932, Test Accuracy: 85.71%\n",
      "Epoch 17/32: Train Loss: 0.3758, Test Loss: 0.4556, Test Accuracy: 80.00%\n",
      "Epoch 18/32: Train Loss: 0.2713, Test Loss: 0.5102, Test Accuracy: 80.00%\n",
      "Epoch 19/32: Train Loss: 0.2864, Test Loss: 0.4996, Test Accuracy: 80.00%\n",
      "Epoch 20/32: Train Loss: 0.2398, Test Loss: 0.3798, Test Accuracy: 82.86%\n",
      "Epoch 21/32: Train Loss: 0.2135, Test Loss: 0.5613, Test Accuracy: 74.29%\n",
      "Epoch 22/32: Train Loss: 0.2636, Test Loss: 0.4151, Test Accuracy: 82.86%\n",
      "Epoch 23/32: Train Loss: 0.3054, Test Loss: 0.4700, Test Accuracy: 82.86%\n",
      "Epoch 24/32: Train Loss: 0.1916, Test Loss: 0.5996, Test Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Define constants\n",
    "image_size = 224\n",
    "batch_size = 8\n",
    "num_epochs = 32\n",
    "learning_rate = 0.001\n",
    "num_classes = 4\n",
    "dropout = 0.5\n",
    "\n",
    "# Load the images in the training directory\n",
    "train_dir = \"./../../Project 3/data/Data_cleaning_step1_2/Train\"\n",
    "test_dir = \"./../../Project 3/data/Data_cleaning_step1_2/Test\"\n",
    "\n",
    "# Define the transformations for train data before entering the neural network\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                                    # Resize images to 224x224 pixels\n",
    "    transforms.RandomCrop(size=image_size),                                         # Randomly crop and resize images to 224x224 pixels\n",
    "    transforms.RandomHorizontalFlip(),                                              # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(30),                                                  # Randomly rotate the images by 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor(),                                                          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])                 # Normalize the images\n",
    "])\n",
    "\n",
    "# Define the transformations for test data before entering the neural network\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),                                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform_train)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test datasets\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Resnet model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Training function\n",
    "def train(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(train_loader), accuracy\n",
    "\n",
    "\n",
    "# Test function for validation and test sets\n",
    "def test(model, criterion, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(loader), accuracy\n",
    "\n",
    "# Initialize the best loss variable with infinity\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "    val_loss, val_accuracy = test(model, criterion, val_loader, device)\n",
    "\n",
    "    scheduler.step(test_loss) \n",
    "\n",
    "    scheduler.step(test_loss) \n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "    \n",
    "    # save model \n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_model_1.pth')\n",
    "\n",
    "data = {\n",
    "    \"Model type\": \"resnet18\",\n",
    "    \"Dataset use\": os.path.basename(train_dir),\n",
    "    \"Image Resize\": str(image_size)+\"*\"+str(image_size),\n",
    "    \"Epochs\": num_epochs,\n",
    "    \"Learning rate\": learning_rate,\n",
    "    \"Batch size\": batch_size,\n",
    "    \"Train Accuracy\": f\"{train_accuracy:.2f}\",\n",
    "    \"Validation accuracy\": f\"{val_accuracy:.2f}\",\n",
    "    \"Test Accuracy\": f\"{test_accuracy:.2f}\",\n",
    "}\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.isfile(\"model_data.csv\"):\n",
    "    existing_data = pd.read_csv(\"model_data.csv\")\n",
    "    new_data = pd.concat([existing_data, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "else:\n",
    "    new_data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "new_data.to_csv(\"model_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0dd26-59a4-4776-b6ec-c302d67b5a26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "resnet_type = \"resnet18\"\n",
    "image_size = 224\n",
    "batch_size = 8\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "num_classes = 4\n",
    "start_time = time.time()\n",
    "\n",
    "train_dir = \"./../Project 3/apple_disease_classification/Train\"\n",
    "test_dir = \"./../Project 3/apple_disease_classification/Test\"\n",
    "\n",
    "# Define the transformations for train data before entering the neural network\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                                    # Resize images to 224x224 pixels\n",
    "    transforms.RandomCrop(size=image_size),                                         # Randomly crop and resize images to 224x224 pixels\n",
    "    transforms.RandomHorizontalFlip(),                                              # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(30),                                                  # Randomly rotate the images by 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor(),                                                          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])                 # Normalize the images\n",
    "])\n",
    "\n",
    "# Define the transformations for test data before entering the neural network\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),                                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform_train)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test datasets\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Resnet model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "def train(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(train_loader), accuracy\n",
    "\n",
    "\n",
    "def test(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(test_loader), accuracy\n",
    "\n",
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(val_loader), accuracy\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "    val_loss, val_accuracy = validate(model, criterion, val_loader, device)\n",
    "\n",
    "    scheduler.step(test_loss) \n",
    "\n",
    "    print(f'Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_model_1.pth')\n",
    "\n",
    "        \n",
    "# Set a time and date\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(timestamp)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "duration_str = time.strftime(\"%H:%M:%S\", time.gmtime(duration))\n",
    "print(f\"Total duration: {duration_str}\")\n",
    "        \n",
    "data = {\n",
    "    \"Timestamp\": timestamp,\n",
    "    \"Duration\": duration_str,\n",
    "    \"Model type\": resnet_type,\n",
    "    \"Dataset use\": os.path.basename(train_dir),\n",
    "    \"Image Resize\": str(image_size)+\"*\"+str(image_size),\n",
    "    \"Epochs\": num_epochs,\n",
    "    \"Learning rate\": learning_rate,\n",
    "    \"Batch size\": batch_size,\n",
    "    \"Train Accuracy\": f\"{train_accuracy:.2f}\",\n",
    "    \"Validation accuracy\": f\"{val_accuracy:.2f}\",\n",
    "    \"Test Accuracy\": f\"{test_accuracy:.2f}\",\n",
    "}\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.isfile(\"model_data.csv\"):\n",
    "    existing_data = pd.read_csv(\"model_data.csv\")\n",
    "    new_data = pd.concat([existing_data, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "else:\n",
    "    new_data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "new_data.to_csv(\"model_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330481a-5390-43b7-9f8b-d3396a2caa5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x