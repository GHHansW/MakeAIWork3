{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711a9757-ca75-417e-b235-caaad9ea3bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HansW\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HansW\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Resnet_Weigth_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_features, num_classes)\n\u001b[0;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 29\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mResnet_Weigth_best.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# # model = CNNModel(num_classes, image_size, dropout)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# model = torch.load('./Team_Complate_Model_2.pth')\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# model = model.to(device)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Define the transformations for test data before entering the neural network\u001b[39;00m\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\mitwworkspace\\MakeAIWork2\\env\\lib\\site-packages\\torch\\serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Resnet_Weigth_best.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet18\n",
    "import random\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "num_classes = 4\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "dropout = 0.5\n",
    "\n",
    "# Resnet model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('Resnet_Weigth_best.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# # model = CNNModel(num_classes, image_size, dropout)\n",
    "# model = torch.load('./Team_Complate_Model_2.pth')\n",
    "# model = model.to(device)\n",
    "# # model.load_state_dict(torch.load('./Team_Weith_Model_1.pth'))\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# Define the transformations for test data before entering the neural network\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),                                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Load dataset path\n",
    "test_dir = \"C:/Users/Lenovo/MakeAIWork3/images/Test1\"\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(test_dir, transform=transform_test)\n",
    "\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "test_dataset = random.sample(test_dataset, k=100)\n",
    "\n",
    "# Create DataLoader for managing the test data batches\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# def test(model, criterion, test_loader, device):\n",
    "#     model.eval()\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs = inputs.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             _, predicted = torch.max(outputs.data, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#     accuracy = 100.0 * correct / total\n",
    "#     return running_loss / len(test_loader), accuracy\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "# print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "quantity = 0\n",
    "# Iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(inputs)  # Feed Network\n",
    "    output = torch.argmax(torch.exp(output), dim=1).cpu().numpy()\n",
    "\n",
    "        \n",
    "    y_pred.extend(output)  # Save Prediction\n",
    "    labels = labels.cpu().numpy()\n",
    "    y_true.extend(labels)  # Save Truth\n",
    "\n",
    "# Class labels\n",
    "classes = ('0', '1', '2', '3')\n",
    "test_dataset.class_to_idx\n",
    "idx2class = {v: k for k, v in test_dataset.class_to_idx.items()}\n",
    "\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "print(quantity)\n",
    "\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix(y_true, y_pred)).rename(columns=idx2class, index=idx2class)\n",
    "# confusion_matrix_df = pd.DataFrame(cf_matrix, columns=classes, index=classes)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix_df, annot=True, ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ead876d-993b-4e6d-8843-cb7107f92f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "3\n",
      "15\n",
      "14\n",
      "18\n",
      "47\n",
      "50\n",
      "{'normal': 3, 'blotched': 15, 'rotten': 14, 'scab': 18}\n",
      "50\n",
      "% slechte appels: 94.0\n",
      "Klasse 4: naar de varkens ermee!\n"
     ]
    }
   ],
   "source": [
    "sample32 = random.sample(y_pred, k=50)\n",
    "\n",
    "# print(sample32)\n",
    "print(len(sample32))\n",
    "\n",
    "Blotch_Apple = 0\n",
    "Normal_Apple= 0\n",
    "Rot_Apple = 0\n",
    "Scab_Apple= 0\n",
    "amount_bad = 0\n",
    "\n",
    "for i in sample32:\n",
    "    if i == 1:  # good apple\n",
    "        Normal_Apple += 1\n",
    "    elif i == 0:\n",
    "        Blotch_Apple += 1\n",
    "        amount_bad += 1\n",
    "    elif i == 2:\n",
    "        Rot_Apple += 1\n",
    "        amount_bad += 1      \n",
    "    else:\n",
    "        Scab_Apple += 1\n",
    "        amount_bad += 1 \n",
    "print(Normal_Apple)   \n",
    "print(Blotch_Apple)   \n",
    "print(Rot_Apple)   \n",
    "print(Scab_Apple)  \n",
    "print(amount_bad)   \n",
    "print(Normal_Apple + amount_bad)\n",
    "\n",
    "outcome_dict= {'normal': Normal_Apple, 'blotched': Blotch_Apple, 'rotten': Rot_Apple, 'scab': Scab_Apple}\n",
    "print(outcome_dict)\n",
    "\n",
    "tot_num_outcome_dict = len(sample32)\n",
    "print(tot_num_outcome_dict)\n",
    "\n",
    "perc_bad_apples = (amount_bad/len(sample32))*100\n",
    "print(f'% slechte appels: {perc_bad_apples}')\n",
    "\n",
    "if perc_bad_apples <= 0.4:\n",
    "    print('Klasse 1: naar supermarkt')\n",
    "elif perc_bad_apples > 0.4 and perc_bad_apples < 6.5:\n",
    "    print('Klasse 2: naar appelmoesfabriek')\n",
    "elif perc_bad_apples >= 6.5 and perc_bad_apples < 15:\n",
    "    print('Klasse 3: naar appelstroopfabriek')\n",
    "else:\n",
    "    print('Klasse 4: naar de varkens ermee!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64b279ee-a6ba-44d6-be11-dc5dc873d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de553b27-c6b0-4ab6-8743-f0c0a07c3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Can you tell me the total number of apples in the batch?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat bot: The total number of apples in the batch is 50.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What is the percentage of bad apples?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat bot: The percentage of bad apples is 94.00%.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  How many bad apples are there in an approved batch?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat bot: The number of bad apples in an approved batch is 47.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  How many apples are categorized as blotch?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat bot: The number of apples categorized as blotch is 15.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Does the quality of the batch increase when the batch size is increased?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat bot: The quality of the batch may or may not increase when the batch size is increased. It depends on various factors.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Load the pre-trained sentence transformer model\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "\n",
    "# Define a list of sample questions\n",
    "questions = [\n",
    "    \"Can you tell me the total number of apples in the batch?\",\n",
    "    \"What is the percentage of bad apples?\",\n",
    "    \"How many bad apples are there in an approved batch?\",\n",
    "    \"How many apples are categorized as blotch?\",\n",
    "    \"What is the proportion of rotten apples?\",\n",
    "    \"Can we use this apple batch to make apple mousse?\",\n",
    "    \"Are there enough healthy apples to make apple sauce?\",\n",
    "    \"Can we use this batch for the supermarket if the acceptance quality is increased by 1 percentage for the klasse 1?\",\n",
    "    \"Does the quality of the batch increase when the batch size is increased?\",\n",
    "    \"What’s the average ratio between the healthy and unhealthy apples for different sample sizes?\"\n",
    "]\n",
    "\n",
    "# Calculate sentence embeddings for the questions\n",
    "question_embeddings = model.encode(questions)\n",
    "\n",
    "# Define the answers corresponding to each question\n",
    "answers = [\n",
    "    f\"The total number of apples in the batch is {len(sample32)}.\",\n",
    "    f\"The percentage of bad apples is {perc_bad_apples:.2f}%.\",\n",
    "    f\"The number of bad apples in an approved batch is {amount_bad}.\",\n",
    "    f\"The number of apples categorized as blotch is {Blotch_Apple}.\",\n",
    "    f\"The proportion of rotten apples is {Rot_Apple / tot_num_outcome_dict:.2f}.\",\n",
    "    \"Yes, we can use this apple batch to make apple mousse.\",\n",
    "    \"To make apple sauce, we need to evaluate the number of healthy apples based on the desired quantity.\",\n",
    "    \"If the acceptance quality is increased by 1 percentage for klasse 1, we can use this batch for the supermarket.\",\n",
    "    \"The quality of the batch may or may not increase when the batch size is increased. It depends on various factors.\",\n",
    "    \"The average ratio between healthy and unhealthy apples can be calculated based on different sample sizes.\"\n",
    "]\n",
    "\n",
    "# Define a function to get the most similar question and its corresponding answer\n",
    "def get_answer(user_query):\n",
    "    query_embedding = model.encode([user_query]).flatten()  # Flatten the query_embedding\n",
    "    similarities = [1 - cosine(query_embedding, q_emb) for q_emb in question_embeddings]\n",
    "    most_similar_idx = similarities.index(max(similarities))\n",
    "    return answers[most_similar_idx]\n",
    "\n",
    "# Chat bot loop\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Chat bot: Goodbye!\")\n",
    "        break\n",
    "    else:\n",
    "        response = get_answer(user_input)\n",
    "        print(\"Chat bot:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
